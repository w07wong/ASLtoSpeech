# ASL Sign to Text Interface

Starting from a conversation about how the Amazon Echo couldn't be used by individuals suffering from muteness, we developed our idea for a sign language translator somewhat backwards. First, we thought about how these individuals communicated in public. Currently, there exist several ways. While it is possible for them to write down their thoughts for others to read, this is a rather impersonal and utilitarian approach to communication. Nonetheless, it does work. The primary mode of communication for such people, however, is ASL, the American Sign Language. An immensely popular mode of communication among mute and otherwise verbally-impaired individuals, the language remains surprisingly unknown to the majority of people who can speak, creating a hidden language gap between the able and the unable. Our ASL Sign-to-Speech interface aims to be the first step at bridging this gap, helping the verbally impaired become more intrinsically connected to the world around them.

Our interface allows users to record and/or train any number of signs and store them locally. As each gesture is saved, it now also becomes recognizable, and the web app will start to begin verbalizing the letter or phrase as it is performed. When the application receives sufficient data, it is possible to form words from letters and sentences from words, given practice. The words each gesture are assigned to are readout twice over- once through the computer's speakers and once through a connected Amazon Echo. Of the two, it is clear Echo's text-to-speech sounds better, but we didn't want to deny people without the Echo the opportunity to use our app as well.
